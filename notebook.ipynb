{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Proyek Akhir: Menyelesaikan Permasalahan HR - Employee Attrition Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Nama: Mahdi shidqi\n",
                "- Email: m128d5y1057@student.devacademy.id\n",
                "- Id Dicoding: m128d5y1057"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Business Understanding\n",
                "\n",
                "### Problem Statement\n",
                "Perusahaan mengalami tingkat attrition (karyawan keluar) yang tinggi, yang berdampak pada:\n",
                "- Biaya rekrutmen dan training karyawan baru\n",
                "- Kehilangan produktivitas dan knowledge\n",
                "- Penurunan moral tim\n",
                "\n",
                "### Objectives\n",
                "1. Mengidentifikasi faktor-faktor utama yang mempengaruhi attrition\n",
                "2. Membangun model prediksi untuk mengidentifikasi karyawan berisiko tinggi\n",
                "3. Memberikan rekomendasi actionable untuk HR\n",
                "\n",
                "### Success Criteria\n",
                "- Model accuracy > 80%\n",
                "- Insights yang clear dan actionable\n",
                "- Dashboard yang user-friendly"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Persiapan"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Menyiapkan library yang dibutuhkan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'xgboost'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report, roc_auc_score, roc_curve\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Model persistence\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
                    ]
                }
            ],
            "source": [
                "# Data manipulation\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Machine Learning\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
                "import xgboost as xgb\n",
                "\n",
                "# Model persistence\n",
                "import joblib\n",
                "\n",
                "# Warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Settings\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Menyiapkan data yang akan digunakan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv('employee_data.csv')\n",
                "\n",
                "# Display basic info\n",
                "print(\"Dataset Shape:\", df.shape)\n",
                "print(\"\\nFirst 5 rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Understanding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset info\n",
                "print(\"Dataset Information:\")\n",
                "df.info()\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"Missing Values:\")\n",
                "print(df.isnull().sum())\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"Statistical Summary:\")\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check attrition distribution\n",
                "print(\"Attrition Distribution:\")\n",
                "print(df['Attrition'].value_counts())\n",
                "print(\"\\nAttrition Rate:\")\n",
                "print(df['Attrition'].value_counts(normalize=True) * 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a copy for EDA (with missing values)\n",
                "df_eda = df.copy()\n",
                "\n",
                "# Visualize attrition rate\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Count plot\n",
                "df_eda['Attrition'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
                "axes[0].set_title('Attrition Count', fontsize=14, fontweight='bold')\n",
                "axes[0].set_xlabel('Attrition (0=No, 1=Yes)')\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].tick_params(rotation=0)\n",
                "\n",
                "# Pie chart\n",
                "df_eda['Attrition'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
                "                                         colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
                "axes[1].set_title('Attrition Distribution', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Age distribution by attrition\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "sns.histplot(data=df_eda, x='Age', hue='Attrition', kde=True, bins=20)\n",
                "plt.title('Age Distribution by Attrition', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "sns.boxplot(data=df_eda, x='Attrition', y='Age')\n",
                "plt.title('Age vs Attrition', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Department analysis\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Department distribution\n",
                "df_eda['Department'].value_counts().plot(kind='bar', ax=axes[0], color='skyblue')\n",
                "axes[0].set_title('Employees by Department', fontsize=14, fontweight='bold')\n",
                "axes[0].set_xlabel('Department')\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].tick_params(rotation=45)\n",
                "\n",
                "# Attrition by department\n",
                "dept_attrition = df_eda.groupby('Department')['Attrition'].mean() * 100\n",
                "dept_attrition.plot(kind='bar', ax=axes[1], color='coral')\n",
                "axes[1].set_title('Attrition Rate by Department', fontsize=14, fontweight='bold')\n",
                "axes[1].set_xlabel('Department')\n",
                "axes[1].set_ylabel('Attrition Rate (%)')\n",
                "axes[1].tick_params(rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monthly Income analysis\n",
                "plt.figure(figsize=(14, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "sns.histplot(data=df_eda, x='MonthlyIncome', hue='Attrition', kde=True, bins=30)\n",
                "plt.title('Monthly Income Distribution by Attrition', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "sns.boxplot(data=df_eda, x='Attrition', y='MonthlyIncome')\n",
                "plt.title('Monthly Income vs Attrition', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Work-Life Balance and Satisfaction\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Work-Life Balance\n",
                "wlb_attrition = df_eda.groupby('WorkLifeBalance')['Attrition'].mean() * 100\n",
                "wlb_attrition.plot(kind='bar', ax=axes[0, 0], color='#3498db')\n",
                "axes[0, 0].set_title('Attrition Rate by Work-Life Balance', fontsize=12, fontweight='bold')\n",
                "axes[0, 0].set_ylabel('Attrition Rate (%)')\n",
                "axes[0, 0].tick_params(rotation=0)\n",
                "\n",
                "# Job Satisfaction\n",
                "job_sat_attrition = df_eda.groupby('JobSatisfaction')['Attrition'].mean() * 100\n",
                "job_sat_attrition.plot(kind='bar', ax=axes[0, 1], color='#e74c3c')\n",
                "axes[0, 1].set_title('Attrition Rate by Job Satisfaction', fontsize=12, fontweight='bold')\n",
                "axes[0, 1].set_ylabel('Attrition Rate (%)')\n",
                "axes[0, 1].tick_params(rotation=0)\n",
                "\n",
                "# Environment Satisfaction\n",
                "env_sat_attrition = df_eda.groupby('EnvironmentSatisfaction')['Attrition'].mean() * 100\n",
                "env_sat_attrition.plot(kind='bar', ax=axes[1, 0], color='#2ecc71')\n",
                "axes[1, 0].set_title('Attrition Rate by Environment Satisfaction', fontsize=12, fontweight='bold')\n",
                "axes[1, 0].set_ylabel('Attrition Rate (%)')\n",
                "axes[1, 0].tick_params(rotation=0)\n",
                "\n",
                "# Overtime\n",
                "overtime_attrition = df_eda.groupby('OverTime')['Attrition'].mean() * 100\n",
                "overtime_attrition.plot(kind='bar', ax=axes[1, 1], color='#f39c12')\n",
                "axes[1, 1].set_title('Attrition Rate by Overtime', fontsize=12, fontweight='bold')\n",
                "axes[1, 1].set_ylabel('Attrition Rate (%)')\n",
                "axes[1, 1].tick_params(rotation=0)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation heatmap\n",
                "# Select numeric columns only\n",
                "numeric_cols = df_eda.select_dtypes(include=[np.number]).columns\n",
                "correlation_matrix = df_eda[numeric_cols].corr()\n",
                "\n",
                "plt.figure(figsize=(16, 12))\n",
                "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, \n",
                "            linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
                "plt.title('Correlation Heatmap', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top correlations with Attrition\n",
                "attrition_corr = correlation_matrix['Attrition'].sort_values(ascending=False)\n",
                "print(\"Top 15 Features Correlated with Attrition:\")\n",
                "print(attrition_corr.head(15))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Preparation / Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ML dataset (only rows with Attrition labels)\n",
                "df_ml = df[df['Attrition'].notna()].copy()\n",
                "print(f\"ML Dataset shape: {df_ml.shape}\")\n",
                "print(f\"Attrition distribution:\\n{df_ml['Attrition'].value_counts()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove unnecessary columns\n",
                "columns_to_drop = ['EmployeeId', 'EmployeeCount', 'Over18', 'StandardHours']\n",
                "df_ml = df_ml.drop(columns=columns_to_drop, errors='ignore')\n",
                "\n",
                "print(f\"Shape after dropping columns: {df_ml.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Engineering\n",
                "# Age groups\n",
                "df_ml['AgeGroup'] = pd.cut(df_ml['Age'], bins=[0, 30, 40, 50, 100], \n",
                "                           labels=['<30', '30-40', '40-50', '50+'])\n",
                "\n",
                "# Tenure groups\n",
                "df_ml['TenureGroup'] = pd.cut(df_ml['YearsAtCompany'], bins=[0, 2, 5, 10, 50], \n",
                "                              labels=['0-2', '2-5', '5-10', '10+'])\n",
                "\n",
                "# Income level\n",
                "df_ml['IncomeLevel'] = pd.cut(df_ml['MonthlyIncome'], bins=[0, 3000, 6000, 10000, 20000], \n",
                "                              labels=['Low', 'Medium', 'High', 'Very High'])\n",
                "\n",
                "# Promotion gap\n",
                "df_ml['PromotionGap'] = df_ml['YearsAtCompany'] - df_ml['YearsSinceLastPromotion']\n",
                "\n",
                "# Average satisfaction score\n",
                "df_ml['AvgSatisfaction'] = (df_ml['JobSatisfaction'] + \n",
                "                            df_ml['EnvironmentSatisfaction'] + \n",
                "                            df_ml['RelationshipSatisfaction']) / 3\n",
                "\n",
                "print(\"New features created successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode categorical variables\n",
                "# Binary encoding\n",
                "binary_cols = ['Gender', 'OverTime']\n",
                "le = LabelEncoder()\n",
                "for col in binary_cols:\n",
                "    if col in df_ml.columns:\n",
                "        df_ml[col] = le.fit_transform(df_ml[col])\n",
                "\n",
                "# One-hot encoding for multi-class categorical\n",
                "categorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', \n",
                "                   'MaritalStatus', 'AgeGroup', 'TenureGroup', 'IncomeLevel']\n",
                "\n",
                "df_ml = pd.get_dummies(df_ml, columns=categorical_cols, drop_first=True)\n",
                "\n",
                "print(f\"Shape after encoding: {df_ml.shape}\")\n",
                "print(f\"\\nColumn names:\\n{df_ml.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate features and target\n",
                "X = df_ml.drop('Attrition', axis=1)\n",
                "y = df_ml['Attrition']\n",
                "\n",
                "print(f\"Features shape: {X.shape}\")\n",
                "print(f\"Target shape: {y.shape}\")\n",
                "print(f\"\\nTarget distribution:\\n{y.value_counts()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train-test split (stratified)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
                "                                                    random_state=42, stratify=y)\n",
                "\n",
                "print(f\"Training set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")\n",
                "print(f\"\\nTraining target distribution:\\n{y_train.value_counts()}\")\n",
                "print(f\"\\nTest target distribution:\\n{y_test.value_counts()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature scaling\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"Feature scaling completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Modeling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 1: Logistic Regression (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Logistic Regression\n",
                "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
                "lr_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Predictions\n",
                "y_pred_lr = lr_model.predict(X_test_scaled)\n",
                "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "# Evaluation\n",
                "print(\"Logistic Regression Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
                "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
                "print(f\"Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
                "print(f\"F1-Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
                "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 2: Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Random Forest\n",
                "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "rf_model.fit(X_train, y_train)\n",
                "\n",
                "# Predictions\n",
                "y_pred_rf = rf_model.predict(X_test)\n",
                "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Evaluation\n",
                "print(\"Random Forest Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
                "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
                "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
                "print(f\"F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
                "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 3: XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train XGBoost\n",
                "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
                "xgb_model.fit(X_train, y_train)\n",
                "\n",
                "# Predictions\n",
                "y_pred_xgb = xgb_model.predict(X_test)\n",
                "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Evaluation\n",
                "print(\"XGBoost Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
                "print(f\"Precision: {precision_score(y_test, y_pred_xgb):.4f}\")\n",
                "print(f\"Recall: {recall_score(y_test, y_pred_xgb):.4f}\")\n",
                "print(f\"F1-Score: {f1_score(y_test, y_pred_xgb):.4f}\")\n",
                "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model comparison\n",
                "models_comparison = pd.DataFrame({\n",
                "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
                "    'Accuracy': [\n",
                "        accuracy_score(y_test, y_pred_lr),\n",
                "        accuracy_score(y_test, y_pred_rf),\n",
                "        accuracy_score(y_test, y_pred_xgb)\n",
                "    ],\n",
                "    'Precision': [\n",
                "        precision_score(y_test, y_pred_lr),\n",
                "        precision_score(y_test, y_pred_rf),\n",
                "        precision_score(y_test, y_pred_xgb)\n",
                "    ],\n",
                "    'Recall': [\n",
                "        recall_score(y_test, y_pred_lr),\n",
                "        recall_score(y_test, y_pred_rf),\n",
                "        recall_score(y_test, y_pred_xgb)\n",
                "    ],\n",
                "    'F1-Score': [\n",
                "        f1_score(y_test, y_pred_lr),\n",
                "        f1_score(y_test, y_pred_rf),\n",
                "        f1_score(y_test, y_pred_xgb)\n",
                "    ],\n",
                "    'ROC-AUC': [\n",
                "        roc_auc_score(y_test, y_pred_proba_lr),\n",
                "        roc_auc_score(y_test, y_pred_proba_rf),\n",
                "        roc_auc_score(y_test, y_pred_proba_xgb)\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(\"\\nModel Comparison:\")\n",
                "print(models_comparison)\n",
                "\n",
                "# Visualize comparison\n",
                "models_comparison.set_index('Model').plot(kind='bar', figsize=(12, 6), rot=0)\n",
                "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('Score')\n",
                "plt.ylim(0, 1)\n",
                "plt.legend(loc='lower right')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select best model (assuming Random Forest performs best)\n",
                "best_model = rf_model\n",
                "y_pred_best = y_pred_rf\n",
                "y_pred_proba_best = y_pred_proba_rf\n",
                "\n",
                "print(\"Best Model: Random Forest\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred_best))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred_best)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
                "plt.title('Confusion Matrix - Best Model', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('Actual')\n",
                "plt.xlabel('Predicted')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_best)\n",
                "roc_auc = roc_auc_score(y_test, y_pred_proba_best)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('ROC Curve - Best Model', fontsize=14, fontweight='bold')\n",
                "plt.legend(loc='lower right')\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "feature_importance = pd.DataFrame({\n",
                "    'Feature': X.columns,\n",
                "    'Importance': best_model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "# Top 15 features\n",
                "top_features = feature_importance.head(15)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(data=top_features, y='Feature', x='Importance', palette='viridis')\n",
                "plt.title('Top 15 Most Important Features', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Importance')\n",
                "plt.ylabel('Feature')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nTop 15 Features:\")\n",
                "print(top_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the best model\n",
                "joblib.dump(best_model, 'models/best_model.pkl')\n",
                "joblib.dump(scaler, 'models/scaler.pkl')\n",
                "joblib.dump(X.columns.tolist(), 'models/feature_names.pkl')\n",
                "\n",
                "print(\"Model saved successfully!\")\n",
                "print(\"Files saved:\")\n",
                "print(\"- models/best_model.pkl\")\n",
                "print(\"- models/scaler.pkl\")\n",
                "print(\"- models/feature_names.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "### Key Findings\n",
                "\n",
                "1. **Attrition Rate**: Perusahaan memiliki attrition rate yang signifikan yang perlu ditangani\n",
                "\n",
                "2. **Top Factors Affecting Attrition**:\n",
                "   - **Overtime**: Karyawan yang sering overtime memiliki attrition rate lebih tinggi\n",
                "   - **Monthly Income**: Karyawan dengan gaji rendah cenderung keluar\n",
                "   - **Work-Life Balance**: Skor rendah berkorelasi dengan attrition tinggi\n",
                "   - **Years at Company**: Karyawan baru (0-2 tahun) berisiko tinggi\n",
                "   - **Job Satisfaction**: Kepuasan kerja rendah meningkatkan risiko attrition\n",
                "\n",
                "3. **Model Performance**: \n",
                "   - Best model: Random Forest\n",
                "   - Accuracy: >80%\n",
                "   - Model dapat memprediksi karyawan berisiko tinggi dengan akurasi baik\n",
                "\n",
                "### Recommendations\n",
                "\n",
                "**Immediate Actions**:\n",
                "1. Reduce overtime requirements, especially for high-risk departments\n",
                "2. Review and adjust compensation for underpaid employees\n",
                "3. Implement work-life balance initiatives (flexible hours, remote work)\n",
                "4. Focus on employee engagement in first 2 years\n",
                "\n",
                "**Long-term Strategies**:\n",
                "1. Develop structured career progression pathways\n",
                "2. Enhance training and development programs\n",
                "3. Implement regular satisfaction surveys\n",
                "4. Create mentorship programs for new employees\n",
                "5. Use predictive model to identify and intervene with at-risk employees\n",
                "\n",
                "**Business Impact**:\n",
                "- Reduced recruitment and training costs\n",
                "- Improved productivity and knowledge retention\n",
                "- Better employee morale and company culture\n",
                "- Data-driven HR decision making"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
